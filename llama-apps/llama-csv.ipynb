{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain_community faiss-cpu langchain-huggingface pymupdf tiktoken langchain-ollama python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(os.environ['LANGSMITH_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import CSVLoader\n",
    "# loader = CSVLoader('./data/data.csv', csv_args={\n",
    "#                                                         'delimiter': ',',\n",
    "#                                                         'quotechar': '\"',\n",
    "#                                                         'fieldnames': [\"Store\",\"Brand\",\"Product_Category\",\"State\",\"Sales\"]\n",
    "#                                                     })\n",
    "# docs = loader.load()\n",
    "# docs[1].page_content\n",
    "# pdf_loader = PyMuPDFLoader('./data/kaynes.pdf')\n",
    "# docs = pdf_loader.load()\n",
    "# doc = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file to be added data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "docs = []\n",
    "for root, dirs, files in os.walk('./data'):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            print('file to be added', file)\n",
    "            loader = CSVLoader(file_path=os.path.join(root, file),\n",
    "                                                    csv_args={\n",
    "                                                        'delimiter': ',',\n",
    "                                                        'quotechar': '\"',\n",
    "                                                        'fieldnames': [\"Store\",\"Brand\",\"Product_Category\",\"State\",\"Sales\"]\n",
    "                                                    })\n",
    "            pages = loader.load()\n",
    "            # print(pages[0].page_content)\n",
    "            docs.extend(pages)\n",
    "\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "# len(encoding.encode(docs[0].page_content)), len(encoding.encode(chunks[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\", base_url=\"http://localhost:11434\")\n",
    "single_vector = embeddings.embed_query(\"this is some text data\")\n",
    "len(single_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(len(single_vector))\n",
    "index.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "ids = vector_store.add_documents(documents=chunks)\n",
    "# vector_store.index_to_docstore_id, len(ids)\n",
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_name = \"q3 results\"\n",
    "# vector_store.save_local(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='4334f528-9820-4184-93b3-249740b75e72', metadata={'source': './data/data.csv', 'row': 87}, page_content='Store: Deluxe Supermarket\\nBrand: Hermanos\\nProduct_Category: Other\\nState: USA\\nSales: 100484090.49'),\n",
       " Document(id='50ea81e9-87bf-4353-9503-4aadc8567f5b', metadata={'source': './data/data.csv', 'row': 97}, page_content='Store: Deluxe Supermarket\\nBrand: Jumbo\\nProduct_Category: Food\\nState: USA\\nSales: 43831561.69'),\n",
       " Document(id='e3eeb30f-bc59-4e93-806d-5e74ed1a454d', metadata={'source': './data/data.csv', 'row': 37}, page_content='Store: Deluxe Supermarket\\nBrand: Even Better\\nProduct_Category: Household\\nState: USA\\nSales: 19539909.99'),\n",
       " Document(id='8edc7558-5aed-4eee-ae20-56a04b9afe33', metadata={'source': './data/data.csv', 'row': 7}, page_content='Store: Deluxe Supermarket\\nBrand: Even Better\\nProduct_Category: Drink\\nState: USA\\nSales: 20500599.77'),\n",
       " Document(id='c87d247a-3459-4757-8c31-2ab0e801faf7', metadata={'source': './data/data.csv', 'row': 27}, page_content='Store: Deluxe Supermarket\\nBrand: Even Better\\nProduct_Category: Health and Hygiene\\nState: USA\\nSales: 24625624.67')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How much is the sales of Deluxe Supermarket in USA\"\n",
    "vector_store.search(query=question, search_type=\"similarity\", k=5) # k is the number of results to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={'k': 5,\n",
    "                                                                        'fetch_k': 100,   \n",
    "                                                                        'lambda_mult': 1})\n",
    "\n",
    "# question = \"how was the result of Anant Raj Limited in Q3 2024\"\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG with LLAMA 3.2 on OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:14b', 'created_at': '2025-02-03T06:46:21.268268Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4196591834, 'load_duration': 811668167, 'prompt_eval_count': 4, 'prompt_eval_duration': 2908000000, 'eval_count': 16, 'eval_duration': 474000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-19f920fa-b4ad-4397-8c7e-432203636e39-0', usage_metadata={'input_tokens': 4, 'output_tokens': 16, 'total_tokens': 20})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "# model = ChatOllama(model=\"llama3.2\", base_url=\"http://localhost:11434\")\n",
    "model = ChatOllama(model=\"deepseek-r1:14b\", base_url=\"http://localhost:11434\")\n",
    "model.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\n    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\\n    If you don't know the answer, just say that you don't know.\\n    Answer in bullet points. Make sure your answer is relevant to the question and it is answered from the context only.\\n    Question: {question} \\n    Context: {context} \\n    Answer:\\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Answer in bullet points. Make sure your answer is relevant to the question and it is answered from the context only.\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, I need to figure out the total sales for the Even Better Brand in Deluxe Supermarket based on the provided context. Let me start by going through each piece of information step by step.\\n\\nFirst, I see that there are five entries, all from Deluxe Supermarket and the brand is Even Better. Each entry has a product category and state along with sales figures.\\n\\nI should list out each sale to make sure I don't miss any:\\n\\n1. Food category in Ontario: $25,737,667.35\\n2. Household in Ontario: $5,929,428.36\\n3. Drink in USA: $20,500,599.77\\n4. Food in Canada: $52,675,649.46\\n5. Household in USA: $19,539,909.99\\n\\nWait a second, I notice that entries 4 and 5 are from Canada and the USA respectively. The user is asking about Deluxe Supermarket's sales for Even Better Brand, but they didn't specify the state or country. However, all entries are under Deluxe Supermarket, so I should include all of them to get the total.\\n\\nNow, I'll add up each sale:\\n\\nStarting with $25,737,667.35 (Food Ontario) + $5,929,428.36 (Household Ontario) = $31,667,095.71\\n\\nThen adding $20,500,599.77 (Drink USA): Total now is $52,167,695.48\\n\\nNext, add $52,675,649.46 (Food Canada): New total is $104,843,344.94\\n\\nFinally, adding the last one: $19,539,909.99 (Household USA) brings the total to $124,383,254.93.\\n\\nI should make sure I didn't miss any decimal points or commas. Each amount is correctly added as they are in dollars and cents. It looks like all five entries are included, so this should be the correct total sales for Even Better Brand in Deluxe Supermarket.\\n</think>\\n\\n- **Total Sales of Even Better Brand in Deluxe Supermarket**: $124,383,254.93\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# print(format_docs(docs))\n",
    "rag_chain = (\n",
    "    {\"context\": retriever|format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# question = question = \"How much is the sales of Deluxe Supermarket in USA\"\n",
    "# question = \"What is cumulative sale of Even Better Brand in Deluxe Supermarket\"\n",
    "question = \"How much is the total sale of Even Better Brand in Deluxe Supermarket\"\n",
    "output = rag_chain.invoke(question)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
